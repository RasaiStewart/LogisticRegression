{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of NN_01_LogisticRegression[1].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RasaiStewart/LogisticRegression/blob/main/Copy_of_NN_01_LogisticRegression%5B1%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKA05U5ml3_C"
      },
      "source": [
        "# Logistic Regression with Keras\n",
        "\n",
        "Welcome to your (possibly) first Machine Learning tutorial.\n",
        "\n",
        "We will be using the Logistic Regression (a one-layer Neural Network) to recognise hand written digits in images.\n",
        "\n",
        "The MNIST database of handwritten digits has been a benchmark in Computer Vision for many years. Although it is considered \"solved\" by many today, new algorithms are still tested on it first, and it still serves as a good learning tool.\n",
        "\n",
        "More information on MNIST including results from prominent researchers in the field who developed a variety of models to improve classification accuracy:\n",
        "\n",
        "> http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "Quick intro to Jupyter controls:\n",
        "\n",
        "> Select a cell and Ctrl+Enter - this will execute the selected cell. For more shortcuts, go to Help -> Keyboard Shortcuts\n",
        "\n",
        "> Go through each cell and execute it to see the result\n",
        "\n",
        "Useful links:\n",
        "\n",
        "> https://en.wikipedia.org/wiki/Logistic_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1z-CKIHl3_H"
      },
      "source": [
        "## Import useful code packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYJWsaT8l3_I"
      },
      "source": [
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Import Keras model layers\n",
        "import keras\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Activation\n",
        "from keras.datasets import mnist\n",
        "from keras import optimizers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "#from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Flatten, Dense, Reshape, Softmax\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.optimizers import gradient_descent_v2 \n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyy0FB8ll3_J"
      },
      "source": [
        "## Load the MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWG3QULKl3_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b4e500-aaad-46d6-f6de-9ca6593f3f70"
      },
      "source": [
        "# download and load the MNIST dataset - the file will be downloaded only once and saved in the Anaconda environment\n",
        "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = mnist.load_data()\n",
        "\n",
        "# Print shapes and bounds\n",
        "print('Train set:')\n",
        "print('Sizes:', X_train_raw.shape, y_train_raw.shape)\n",
        "\n",
        "print('Test set:')\n",
        "print('Sizes:', X_test_raw.shape, y_test_raw.shape)\n",
        "\n",
        "print('Image values (min to max):', np.min(X_train_raw), 'to', np.max(X_train_raw))\n",
        "print('Label values (min to max):', np.min(y_train_raw), 'to', np.max(y_train_raw))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set:\n",
            "Sizes: (60000, 28, 28) (60000,)\n",
            "Test set:\n",
            "Sizes: (10000, 28, 28) (10000,)\n",
            "Image values (min to max): 0 to 255\n",
            "Label values (min to max): 0 to 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T47q5a-0l3_K"
      },
      "source": [
        "## Normalisation\n",
        "\n",
        "The data was loaded, but the pixel values are not suitable for learning with a Neural Network. Also, labels have to be in one-hot format.\n",
        "\n",
        "* Divide raw image data in both training and test set by the maximum value\n",
        "\n",
        "* Flatten the images into 1D vectors. Use NumPy's reshape function:\n",
        "    https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\n",
        "\n",
        "* Convert the raw numeric labels (0..9) to one-hot vectors - Keras has a builtin function to do just that:\n",
        "    https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgU9GGSKl3_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46066361-5e3e-4488-f583-add51c2109a6"
      },
      "source": [
        "# normalise raw image data by dividing by the maximum value\n",
        "X_train = X_train_raw / 255 # normalise X_train\n",
        "X_test = X_test_raw / 255 # normalise X_test\n",
        "\n",
        "# flatten normalised data into 1D vectors\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# convert raw labels to one-hot vectors\n",
        "y_train = tf.keras.utils.to_categorical(y_train_raw, num_classes=10) # convert y_train\n",
        "y_test = tf.keras.utils.to_categorical(y_test_raw, num_classes=10) # convert y_test\n",
        "\n",
        "# shuffle training samples (same permutation for X and Y so that labels still correspond)\n",
        "np.random.seed(42) # fix random seed so that everyone has the same dataset permutation\n",
        "permutation = np.random.permutation(X_train.shape[0])\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "# Print shapes and bounds\n",
        "print('### Train set:')\n",
        "print('Sizes:', X_train.shape, y_train.shape)\n",
        "print('Image values (min to max):', np.min(X_train), 'to', np.max(X_train))\n",
        "print('Label values (min to max):', np.min(y_train), 'to', np.max(y_train))\n",
        "print('Total samples per class:', np.sum(y_train, axis=0))\n",
        "\n",
        "print('### Test set:')\n",
        "print('Sizes:', X_test.shape, y_test.shape)\n",
        "print('Image values (min to max):', np.min(X_test), 'to', np.max(X_test))\n",
        "print('Label values (min to max):', np.min(y_test), 'to', np.max(y_test))\n",
        "print('Total samples per class:', np.sum(y_test, axis=0))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Train set:\n",
            "Sizes: (60000, 784) (60000, 10)\n",
            "Image values (min to max): 0.0 to 1.0\n",
            "Label values (min to max): 0.0 to 1.0\n",
            "Total samples per class: [5923. 6742. 5958. 6131. 5842. 5421. 5918. 6265. 5851. 5949.]\n",
            "### Test set:\n",
            "Sizes: (10000, 784) (10000, 10)\n",
            "Image values (min to max): 0.0 to 1.0\n",
            "Label values (min to max): 0.0 to 1.0\n",
            "Total samples per class: [ 980. 1135. 1032. 1010.  982.  892.  958. 1028.  974. 1009.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SChK15vpl3_L"
      },
      "source": [
        "**Expected output:**\n",
        "\n",
        "\\### Train set:<br>\n",
        "Sizes: (60000, 784) (60000, 10)<br>\n",
        "Image values (min to max): 0.0 to 1.0<br>\n",
        "Label values (min to max): 0.0 to 1.0<br>\n",
        "Total samples per class: [5923. 6742. 5958. 6131. 5842. 5421. 5918. 6265. 5851. 5949.]<br>\n",
        "\\### Test set:<br>\n",
        "Sizes: (10000, 784) (10000, 10)<br>\n",
        "Image values (min to max): 0.0 to 1.0<br>\n",
        "Label values (min to max): 0.0 to 1.0<br>\n",
        "Total samples per class: [ 980. 1135. 1032. 1010.  982.  892.  958. 1028.  974. 1009.]<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4RkZSCml3_M"
      },
      "source": [
        "## Plot some samples\n",
        "\n",
        "Change the index to see other samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8GSvvBpl3_N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "4bd16470-51c7-4a38-8a61-617c2b03c4f7"
      },
      "source": [
        "# Just a function to display a sample\n",
        "def display_digit(index, xs, ys, title):\n",
        "    label = np.argmax(ys[index]) # argmax used to convert from one-hot back to numeric label\n",
        "    image = xs[index].reshape([28,28]) # make sure that the data is in 2D shape\n",
        "    plt.title(title+': Index: %d  Label: %d' % (index, label))\n",
        "    plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
        "    plt.show()\n",
        "\n",
        "display_digit(index=0, xs=X_train, ys=y_train, title='Train sample') # display the first training example\n",
        "display_digit(index=0, xs=X_test,  ys=y_test,  title='Test sample')  # display the first test example"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euDXufn7l3_N"
      },
      "source": [
        "That's right, the classes seem very easy to separate ! Let's prepare to train our algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbSOXzJcl3_O"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "We will build a neural network with a single layer:\n",
        "\n",
        "* Use Kera's Dense to create a Fully Connected layer, use 'softmax' activation\n",
        "\n",
        "![](./images/lr_diag.png \"Logistic Regression\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcLO2Jxvl3_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "db9282fd-2a76-4c75-f6e3-6a90b48ace6c"
      },
      "source": [
        "# get input and output sizes\n",
        "input_dim = X_train.shape[1] # 784\n",
        "output_dim = y_train.shape[1] # 10\n",
        "\n",
        "# Create Sequential model - this allows you to add layers one after the other to build your model\n",
        "model = Sequential()\n",
        "model.add(model.add.layers(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "optim = keras.optimizers.SGD(lr=0.01)\n",
        "model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-44b0c75c68cb>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    optim = keras.optimizers.SGD(lr=0.01)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8js-Hlal3_O"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "> **Note**: Be sure to rerun the previous cell before you train, otherwise previous weights will be kept - i.e. you would just train your model further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7u5BZzsl3_P"
      },
      "source": [
        "# settings\n",
        "batch_size = 32\n",
        "nb_epoch = 15\n",
        "\n",
        "# train the model and save training history\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size, \n",
        "          epochs=nb_epoch, \n",
        "          verbose=1, \n",
        "          validation_split=__CODE_HERE__, # set 10K samples (out of 60K) aside for validation\n",
        ")\n",
        "\n",
        "# save model weights to file\n",
        "model.save_weights('mnist_logistic_regression.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VVMSXnTl3_P"
      },
      "source": [
        "## Plot training behaviour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jFypQ0Xl3_P"
      },
      "source": [
        "# summarize history for loss and accuracy\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
        "\n",
        "ax1.plot(history.history['loss'])\n",
        "ax1.plot(history.history['val_loss'])\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.legend(['training', 'validation'], loc='upper right')\n",
        "ax1.yaxis.grid()\n",
        "\n",
        "ax2.plot(history.history['acc'])\n",
        "ax2.plot(history.history['val_acc'])\n",
        "ax2.set_ylabel('accuracy')\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.legend(['training', 'validation'], loc='upper left')\n",
        "ax2.yaxis.grid()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DM_d_iIl3_Q"
      },
      "source": [
        "## Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMiYExnhl3_Q"
      },
      "source": [
        "# load model weights from file\n",
        "model.load_weights('mnist_logistic_regression.h5')\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv75YxQ2l3_Q"
      },
      "source": [
        "You should have obtained a value of around 0.91-0.92 (which means 91%-92% test accuracy). Congratulations !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SwmsZQal3_Q"
      },
      "source": [
        "## Try the following\n",
        "\n",
        "1) Change the learning rate (e.g. 0.0001, 0.001, 0.01, 0.1) and observe the training curves\n",
        "\n",
        "2) Add Momentum to the SGD optimizer (https://keras.io/optimizers/) and observe the accuracy\n",
        "\n",
        "3) Change the batch size (e.g. 8, 16, 32, 64, 128, 256) and see what happens (time per epoch, accuracy, etc)\n",
        "\n",
        "4) Try a different optimizer altogether (e.g. Adam) (https://keras.io/optimizers/)\n",
        "\n",
        "5) Try adding shuffling during training (https://keras.io/models/sequential/)\n",
        "\n",
        "6) Share your best results !"
      ]
    }
  ]
}